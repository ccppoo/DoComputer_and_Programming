# Memory Mapping은 캐시와 관련이 있는가

*메모리 페이징(Memory Paging)은 여기서 다루지 않음

## 서론

메모리 매핑(Memory Mapping)은 물리적으로 존재하는 기억 보조장치(HHD/SSD)으로부터 데이터를 복사한 뒤

휘발성이 있는 메인 메모리(RAM)에 저장한 뒤 접근하는 방식이다.

프로세스가 할당된 가상 메모리에 할당되기 때문에 일반 디스크에 메모리 I/O에 비해 속도의 이점을 가질 수 있다.

그래서 잦은 읽기/쓰기가 이루어지는 파일이 메모리 매핑이 된다.

대표적으로 게임의 경우 그래픽, 로직, 네트워크 세가지를 처리하는 각각의 프로세스가 존재할 경우 I/O 딜레이를 줄이기 위해 사용된다고 보면된다.

메인 메모리의 일부를 저장장치로 이용하는 것인 만큼, 보조 메모리에 있을 법한 사이즈(수십 GB...)는 적절하지 않으며<br>
사용자가 파일의 어느 부분을 매핑할 것인지 인지하고 있어야하며, 본인이 다루고 있는 데이터에 대한 이해가 필요하다.

말 그대로 메모리 주소에 바이트 하나하나를 저장하는 방식이므로 데이터의 형태만 알 수 있다면 다른 프로세스나 시스템 간에 통신하는 용도로도 쓰일 수 있다.

하지만 데이터를 읽는 방식이 보편적인 표준(JPGE, PNG, 등)이 아닌, 특정 회사가 만든 포멧의 경우(pptx, **hwp**) 파일을 읽수 있는 소프트웨어가 따로 필요하기 때문에 적절하지 않다.

아무튼 메모리 매핑은 위에 간단히 서술한 특징 덕분에 IPC, 프로세스 간 통신(Inter-Process Communication) 방법 중 하나로 쓰인다.

## 캐시(Cache) 이야기가 나온 이유

우선 메모리 매핑 도중에 캐시 이야기가 나온 이유는

이렇게 매핑되는 메모리가 캐시 적중률, 캐시 히트(Cache Hit)와 관련이 있는지 궁금증이 떠올랐기 때문이다.

## 캐시는 무엇인가

캐시는 다시 사용할 가능성이 높은 데이터를 저장해 놓은 메모리다.

캐시를 사용하는 주 목적은 지연시간을 낮추기 위해서다.

그리고 방금 말한 **캐시 적중률**(Cache Hit Ratio)는 나중에 다시 사용할 것 같아 저장한 메모리가 얼마만큼 적중했는지, 즉 미리 저장한게 잘 쓰였는지 판단하는 여부다.

캐시가 다시 사용될 수 있는, 즉 효율적으로 사용되는지 판단하는 특성 논리적/물리적 특성으로부터 기반하는데

하나는 최근에 접근한 데이터가 가까운 미래에 또 접근할 가능성이 높다고 판단하는 **시간적 지역성**

다른 하나는 최근에 접근한 데이터들의 주소가 순서대로 접근되었을 경우, 또 접근할 가능성이 높다고 판단하는 **공간적 지역성**이다.

논리적 특성(*한번 쓴 데이터는 여러번 쓰더라*) : 시간적 지역성

공간적 특성(*메모리 주소 순서대로 쭉 읽더라) : 공간적 지역성

## 캐시(Cache) 이야기가 나온 이유 (이어서)

그럼 가상메모리의 일부를 할당해 만든 메모리 매핑된 파일은 프로그래밍과 함께 가상 메모리에 매핑된다.

우선 프로그램과 매핑된 메모리가 *존재하는* 가상 메모리는 실제 물리적 메모리 주소에 *존재하지 않는다*.

하지만 캐시도 가상 주소를 사용하는 가상 캐시(Virtual Cache)와 실제 주소를 사용하는 물리 캐시(Physical Cache)도 있다...

일단, 물리적인 캐시는 가상 메모리 주소를 물리 메모리 주소로 변환하는 MMU(Memory Management Unit) 이후에서의 상황을 다루니깐 가상 캐시에 대해서 계속해서 쓰겠다.

질문을 좀 더 구체적으로 할 수 있게되었다.

**메모리 매핑과 가상 캐시의 캐시 히트를 높이는가?**

## 결론

프로세스가 참조하는 매핑된 메모리는 DRAM 속 페이지 테이블(Page Table)에 저장된다.

페이지 테이블에 물리적 메모리(DRAM)에 없는 경우 Page Miss(DRAM 캐시 미스)가 일어나고,<br>
예외를 처리하기 위해 Page Fault Handler가 호출된다.

핸들러는 페이지 테이블에 적혀있는 보조 기억 장치의 주소로부터 물리적 메모리에 매핑을 한다.

이 과정 속에서 I/O 지연이 발생한다.

즉, 메모리 매핑을 함으로써 캐시 히트를 높인다.

```
일반적인 디스크 I/O:

컨텍스트 전환 -> 가상 메모리 접근 -> 페이지 폴트 ->  I/O 작업 -> CPU 사용률 높이기 위한 컨텍스트 전환(yield)

다시 컨텍스트 전환 -> 페이지 히트(필요한 메모리 매핑되어 있음) -> 작업 수행


메모리 매핑:

메모리 매핑 -> 페이지 히트 -> 작업 수행
```

어차피 해야할 과정을 미리하는 것과 같다.

그리고 I/O 과정에서 프로그래머가 동기(sync)적으로 프로그램을 작성할 경우 지연은 더더욱 눈에 띄게 된다.

## 요약

1. 메모리 매핑과 가상 캐싱(메인 메모리 수준)과 관련 있다.

2. 프로세스가 저장되어 있는 가상 메모리, 페이지(page)에 매핑되어 있으며 미리 매핑하지 않는 경우 최초에 무조건 페이지 폴트가 일어난다.

3. 메모리 매핑은 필요한 데이터만 사용한다는 점에서 리소스 소모도 줄이고 그만큼 처리할 시간이 절약된다.

4. + 메인 메모리에서의 캐시 미스는 CPU의 캐시 미스 패널티에 비해 상당히 크다.

*너무 당연한 이야기를 길게 늘여뜨린 감이 있지만, 추측으로만 모호하게 알고 있는 내용을 더듬는 수준으로 알 수 있게되었다*

## 참고

[CSAPP- Virtual Memory](https://it-eldorado.tistory.com/52)

[Virtual memory caches](https://talkingaboutme.tistory.com/entry/Memory-Virtual-memory-caches)

[페이징 - Wikipedia](https://ko.wikipedia.org/wiki/페이징)

[Virtual Memory - Wekipedia](https://en.wikipedia.org/wiki/Virtual_memory)

[Memory Mapped File - Wekipidia](https://en.wikipedia.org/wiki/Memory-mapped_file)

Memory Mapped I/O는 전혀 다른 개념으로

메인 메모리에 주변기기(마우스, 키보드, 등)가 입력(I/O)할 때 신호를 저장하는 메모리를 부르는 것이다.

추가로 외부 입력기기의 신호를 처리하는 방법으로 Isolated(Ported) I/O는 메인 메모리와 별개로 존재하는 메모리에 신호를 입력하게끔 설계되어 있다.<br>
메인 메모리와 구분되어 있어 포트(port)라고 부르며, 입력된 신호가 I/O로 판단되면 CPU가 메모리 주소를 할당해 사용할 수 있도록 한다는 특징이 있다.